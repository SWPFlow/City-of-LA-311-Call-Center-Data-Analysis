{
    "contents" : "---\ntitle: \"requesting_data\"\nauthor: \"Yu Dong\"\ndate: \"11/29/2016\"\noutput: html_document\n---\n\n# Load dataset\n\nLoad useful packages and the downloaded dataset from https://data.lacity.org/A-Well-Run-City/MyLA311-Service-Request-Data-2016/ndkd-k878\n\n```{r load}\nsetwd(\"~/Desktop/DSO545/Final project\")\n# load(\"processed1.RData\")\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(stringr)\nlibrary(ggmap)\nlibrary(plotly)\nlibrary(choroplethrZip) #https://github.com/arilamstein/choroplethrZip\nrequest_data = read.csv(\"raw data/MyLA311_Service_Request_Data_2016.csv\")\n```\n\n# Preprocessing\n\nPreprocess the data:  \nchange the format of time variables using lubridate package  \n\n```{r preprocess}\nrequest_data$CreatedDate = mdy_hms(request_data$CreatedDate)\nrequest_data$UpdatedDate = mdy_hms(request_data$UpdatedDate)\n# since there are lots of observations like xx/xx/xxxx 12:00:00AM which leads to unaccurate time records, remove the hour-minute_seconds part\nrequest_data$ServiceDate = str_replace_all(request_data$ServiceDate, \" [0-9]{2}:[0-9]{2}:[0-9]{2} [AP]M\", \"\")\nrequest_data$ServiceDate = mdy(request_data$ServiceDate)\n# attention: there are many obviously unreasonable records: many records with service date of 1900/01/01, and some other service dates in 2017 or later\nrequest_data$ClosedDate = mdy_hms(request_data$ClosedDate)\n# adjust data in zipcode column\nrequest_data$ZipCode = str_replace_all(request_data$ZipCode, \"[a-zA-Z ,]*\", \"\")\n```\n\nCalculate new variables:  \n1. extract the month, weekday and hour the request created  \n2. create the response period/ update duration\n\n```{r new variables}\n# extract the month, weekday and hour of CreatedDate\nrequest_data$month_created = month(request_data$CreatedDate)\nrequest_data$weekday_created = wday(request_data$CreatedDate, label = TRUE)\nrequest_data$hour_created = hour(request_data$CreatedDate)\n\n# calculate response period (ClosedDate - CreatedDate)\nrequest_data$response_period = round((request_data$ClosedDate - request_data$CreatedDate) / (60 * 60),2)  # round to 2 digits, in hours\n\n# special attention: the percentage of requests without a ClosedDate: 0.546\nnrow(filter(request_data, is.na(ClosedDate)))/ nrow(request_data)\n\n# caulculate update duration (UpdatedDate - CreatedDate)\nrequest_data$duration = round((request_data$UpdatedDate-request_data$CreatedDate)/(60*60),2)\nrequest_data = mutate(request_data, update_duration = ifelse(duration <= 0, 0, duration))\nrequest_data$duration = NULL\n```\n\n# Trial run for sampled data\n\nSampling 1000 observations from the whole dataset.\n\n```{r sampling}\n# load(\"processed_requests2.RData\")\nset.seed(1)\nsampled_data = sample_n(request_data, 1000)\n```\n\n## Geographical analysis\n\nPlot the contour plot for all the calls, we can find that there are two centers.\n\n```{r map}\nLA_map = qmap(\"Los Angeles\", zoom = 10, maptype = \"road\")\nLA_map + \n    stat_density2d(data = sampled_data,\n                   aes(x = Longitude, y = Latitude, fill = ..level..),\n                   geom = \"polygon\", alpha = 0.3) +\n    scale_fill_gradient(low = \"white\", high = \"darkred\")\n```\n\nAnalysis on zipcode\n\n```{r map2}\nsampled_zip = merge(sampled_data, zipcode, by.x = \"ZipCode\", by.y = \"zip\")\nLA_map +   \n    geom_point(data = sampled_data,\n               aes(x = Longitude, y = Latitude),\n               size = 5, alpha = 0.1, color = \"darkred\")\n\nrequests_zip = sampled_data %>% \n    group_by(ZipCode) %>%\n    filter(!ZipCode %in% c(\"0\", \"\")) %>%\n    summarise(value = n())\ncolnames(requests_zip) = c(\"region\", \"value\") \nzip_vec = unique(requests_zip$region)\n\n# plot all zips in LA\nzip_choropleth(requests_zip,\n               county_zoom=6037, \n               title=\"Requests number by zipcode\",\n               legend=\"Requests numbers\")\n\n# plot only the zips appear in the data\nzip_choropleth(requests_zip, \n               zip_zoom = zip_vec, \n               title=\"Requests number by zipcode\",\n               legend=\"Requests numbers\")\n\n```\n\nPlot for the whole dataset\n\n```{r all data}\nrequest_data_plot = select(request_data, ZipCode, RequestType)\n\nrequests_zip = request_data %>% \n    group_by(ZipCode) %>%\n    filter(!ZipCode %in% c(\"0\", \"\", \"9008\")) %>%\n    summarise(value = n())\ncolnames(requests_zip) = c(\"region\", \"value\") \n\nzip_vec = unique(requests_zip$region)\n\n# plot all zips in LA\nzip_choropleth(requests_zip,\n               county_zoom=6037, \n               title=\"Requests numbers by zipcode\",\n               legend=\"Requests numbers\")\n\n# plot only the zips appear in the data\nzip_choropleth(requests_zip, \n               zip_zoom = zip_vec, \n               title=\"Requests numbers by zipcode\",\n               legend=\"Requests numbers\") +\n    scale_fill_brewer(name=\"Population\", palette=\"OrRd\", drop=FALSE)\n```\n\nContrast with population by zipcode\n\n```{r pop zip}\npopulation_zip = read.csv(\"zip_population_2010_census.csv\")\npopulation_zip = select(population_zip, Zip.Code, Total.Population)\ncolnames(population_zip) = c(\"region\", \"value\")\npopulation_zip$region = as.character(population_zip$region)\nzip_vec2 = unique(population_zip$region)\nzip_choropleth(population_zip, \n               zip_zoom = zip_vec, \n               title=\"Population by zipcode\",\n               legend=\"Population\")\n```\n\nMaking interative plots\n\n```{r plotly}\np1 = zip_choropleth(requests_zip, \n               zip_zoom = zip_vec, \n               title=\"Requests numbers by zipcode\",\n               legend=\"Requests numbers\")\nggplotly(p1)\np2 = zip_choropleth(population_zip, \n               zip_zoom = zip_vec, \n               title=\"Population by zipcode\",\n               legend=\"Population\")\nggplotly(p2)\n```\n\nSummary statistics\n\n```{r stat}\nrequests_zip %>%\n    mutate(requests_prop = round(value / sum(value), 3)) %>%\n    arrange(-requests_prop) %>%\n    top_n(10)\n\npopulation_zip %>%\n    filter(region %in% zip_vec) %>%\n    mutate(pop_prop = round(value / sum(value), 3)) %>%\n    arrange(-pop_prop) %>%\n    top_n(10)\n```\n\nThe requests are more concentrated in certain areas, and there are some differences between the lists of most frequent zipcodes\n\nAnalysis by CD\n\n```{r CD}\nCD_stat = read.csv(\"CD summary statisitcs.csv\")\n\n# calculate total requests number and average update duration\nCD_stat2 = request_data %>%\n    filter(!is.na(CD)) %>%\n    group_by(CD) %>%\n    summarise(count = n(), \n              avg_duration = round(mean(update_duration),2))\n\nCD_summary = merge(CD_stat, CD_stat2, by.x = \"CD\", by.y = \"CD\", all.x = TRUE)\nCD_summary$count[16] = nrow(request_data)\nCD_summary$avg_duration[16] = round(mean(request_data$update_duration),2)\n\nCD_summary$request_pop = round(CD_summary$count / CD_summary$Population.000s., 2)\ncolnames(CD_summary) = c(\"Council District\", \"Population(000s)\", \"Median Age\", \n                         \"Median Household Income($000s)\", \"Unemployment Rate\", \n                         \"Top1 Occupation\", \"Top2 Occupation\", \n                         \"Top3 Occupation\", \"Requests Counts\", \n                         \"Average Update Duration\", \"Requests per 1000 Residents\")\n\nggplot(CD_summary, aes(x = `Unemployment Rate`, y = `Requests per 1000 Residents`)) +\n    geom_point()\n\nggplot(CD_summary, aes(x = Median_hs_income, y = Requests_by_pop)) +\n    geom_point()\n\n```\n\n\n\n## Analysis on request sources and types\n\n## Analysis by time",
    "created" : 1480655501858.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2810113654",
    "id" : "7E0C219D",
    "lastKnownWriteTime" : 1480812851,
    "path" : "~/Desktop/DSO545/Final project/fight-on/requesting_data.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_markdown"
}